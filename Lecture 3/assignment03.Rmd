
# ME314 Managing and Visualizing Data

## Day 3 Assignment, LSE ME314 2018
---

### 1.  Normalizing data

This question uses this table:
![Not normalized data](http://www.essentialsql.com/wp-content/uploads/2014/06/Intro-Table-Not-Normalized.png)

from the lecture notes.  For each answer, please explain as fully as possible, and feel free to use tables or diagrams if you prefer.

a)  Why does this table violate the first normal form, and what would be required to make it 1NF?

**This table violates the first normal form due to the wide format of Customer1, Customer2 and Customer3, indicating repeating group of element.**

**To make it 1NF, create 3 tables:**
  **- Office database that consist of Office ID, Location and Office Number**
  **- Customer database that contains Office ID, Customer name and Employee ID**
  **- Employee database with Employee ID, employee's name and Office ID**

b)  What additional steps would be needed to make the table 2NF, and why?

**After converting the table into 1NF, it still violates the format as there are repeated entries of "Chicago" under "SalesOffice" category. To make it 2NF, construct 2 tables out of the 1NF table, with:**
  **- First table consist of "EmployeeID", "SalesOffice" and "Office Number"**
  **- Second table consist of "EmployeeID" and "Customer" column.**


c)  Why might we not want to normalize data to the fullest extent possible?

**Overnormalization implies an increase in number of joins required in a query between related table. The biggest problem with normalization is that we will end up with multiple tables storing information about a single item. The use of multiple joins to assess information makes the process intensive and slow to take place.**

d)  In the table below, which of the three normalization rules does this violate, if any, and why?

   |  countryID  |  countryName    |   EUmember   |  EUjoindate  |
   | -----------:|:----------------|:------------:|:------------:|
   | 00001       | France          |  `true`      |  1958-01-01  |
   | 00004       | Hungary         |  `true`      |  2004-05-01  |
   | 00003       | Serbia          |  `false`     |       `NULL` |
   | 00004       | Finland         |  `true`      |  1995-01-01  |
   | 00005       | Russia          |  `false`     |       `NULL` |
   | 00006       | Ireland, UK     |  `true`      |  1973-01-01  |

   Are there any other problems with the table, besides normalization?

**The table violates the first normalization rule (1NF) because the "countryName" column has multiple values separated by a comma for the row with "Ireland, UK".**

**Regarding other problems, the "countryID" column has duplicate values (e.g., "00004" appears twice). Additionally, the "EUjoindate" column has null values for the rows with "Serbia" and "Russia".**

e)  What would it take to full (1NF-3NF) normalize this dataset?
**To fully normalize the data to 3NF:**
  **1. 1NF**
      **- Create a separate column for each data in the "countryName" column.**
      **- Create a separate column for each data in the "EUjoindate" column.**
      
         |  countryID  |  countryName1 |  countryName2 |   EUmember   |  EUjoindateYear  |  EUjoindateMonth | EUjoindateDay|
         | -----------:|:--------------|:--------------|:-------------|:-----------------|:-----------------|:-------------|
         | 00001       | France        |               |  `true`      |  1958            |  01              | 01           |
         | 00004       | Hungary       |               |  `true`      |  2004            |  05              | 01           |
         | 00003       | Serbia        |               |  `false`     |                  |                  |              |
         | 00004       | Finland       |               |  `true`      |  1995            |  01              | 01           |
         | 00005       | Russia        |               |  `false`     |                  |                  |              |
         | 00006       | Ireland       |  UK           |  `true`      |  1973            |  01              | 01           |
  
  **2. 2NF**
      **- Create a separate table for the "countryID" and "EUmember" columns, with "countryID" as the primary key.**
      **- Create a separate table for the "countryID", "EUjoindateYear", "EUjoindateMonth", and "EUjoindateDay" columns, with "countryID" as the primary key.**
      
    |  countryID  |  EUmember |
    |------------:|:----------|
    | 00001       |  `true`   |
    | 00004       |  `true`   |
    | 00003       |  `false`  |
    | 00004       |  `true`   |
    | 00005       |  `false`  |
    | 00006       |  `true`   |
      
    |  countryID  |  EUjoindateYear |  EUjoindateMonth  |  EUjoindateDay  |
    |------------:|:----------------|:------------------|:----------------|
    | 00001       |   1958          |   05              |   01            |
    | 00004       |   2004          |   01              |   01            |
    | 00003       |                 |                   |                 |
    | 00004       |   1995          |   05              |   01            |
    | 00005       |                 |                   |                 |
    | 00006       |   1973          |   01              |   01            |
  
   **3. 3NF**
      **There are no transitive dependence in the dataset after 2NF. No transformation needed. The data is already in 3NF.**
      
   Write out these tables, and describe why this meets each of the normal forms.  This is a database of movies watched on NetBricks, a streaming movie service.

   | Name           | Address           |   Movies Rented                             |  Salutation  | Category       |
   |:---------------|:------------------|:--------------------------------------------|:------------:|----------------|
   | Bob Smith      | 1 Houghton Street | _Star Wars_, _Inception_                    |  Dr.         |  Scifi, Scifi  |
   | Pry Ministair  | 10 Downing St     |  _Brexit the Movie_                         |  Lady        | Tragedy        |
   | Joe Bloggs     | 8 Myhatt St.      |  _Fast and Furious 6_, _Fast and Furious 7_ |  Mr.         | Action, Action |

  **This table does not meet the first normal form (1NF) since the Movies Rented column has multiple values in a single cell. To achieve 1NF, we would need to split the Movies Rented column into multiple rows.**

  **To achieve 2NF, we could create a separate table for the Movies Rented column and use a foreign key to link it to the original table. This would ensure that we do not have any repeating groups in our table.**

  **To achieve 3NF, we could further normalize the table by creating separate tables for Salutation and Category, each with their own primary key. We could then use a foreign key to link these tables to our original table.**

  **In the end, the normalized tables might look something like this:**
  
    | CustomerID  | First Name  | Last Name |     | AddressID  | Street            |     | SalutationID  | Salutation  |
    |------------:|:------------|:----------|     | ----------:|:------------------|     |--------------:|:------------|
    | 001         | Bob         | Smith     |     | 001        | 1 Houghton Street |     | 001           | Dr.         |
    | 002         | Pry         | Ministair |     | 002        | 10 Downing St.    |     | 002           | Lady        |
    | 003         | Joe         | Bloggs    |     | 003        | 8 Myhatt St.      |     | 003           | Mr.         |
  
  
    | MovieID | Movie Title         |      | CategoryID | Category |   
    |--------:|:--------------------|      |-----------:|:---------|
    | 001     | Star Wars           |      | 001        | Scifi    |
    | 002     | Inception           |      | 002        | Tragedy  |
    |  003     | Brexit the Movie   |      | 003        | Action   |
    | 004     | Fast and Furious 6  |
    | 005     | Fast and Furious 7  |
  
    |RentalID | NameID | AddressID | MovieID | SalutationID | CategoryID  |
    |--------:|:-------|:----------|:--------|:-------------|:------------|
    | 001     | 001    | 001       | 001     | 001          | 001         |
    | 002     | 001    | 001       | 002     | 001          | 001         |
    | 003     | 002    | 002       | 003     | 002          | 002         |
    | 004     | 003    | 003       | 004     | 003          | 003         |
    | 005     | 003    | 003       | 005     | 003          | 003         |
  
### 2.  Reshaping data

For this exercise, we will use the **nycflights13** R package, whose tables have been output in `.csv` form [here](nycflights13/).  You may do the following in either R or Python.  Note that this example is developed extensively in [_R for Data Science_](http://r4ds.had.co.nz/relational-data.html).

a)  Create a subtable of the `flights` data, that departed before 05:53 on 2013-02-28.  How many rows and columns does this subtable have?  

```{r}
library("dplyr", quietly = TRUE)
library("lubridate", quietly = TRUE)

flights <- read.csv("nycflights13/flights.csv")

#Add a new colum dep_datetime by concatenating year, month, day, hour and minute column
flights$dep_datetime <- ymd_hm(sprintf("%s-%02d-%02d %02d:%02d",
                            flights$year,
                            flights$month,
                            flights$day,
                            flights$hour,
                            flights$minute))

#Subtable of flights data with departure time before 05:53 on 2013-02-28
flights_sub <- subset(flights, dep_datetime < ymd_hm("2013-02-28 05:53"))
head(flights_sub)

cat(paste("Number of rows: ", nrow(flights_sub), '\n'))
cat(paste("Number of columns: ", ncol(flights_sub)))

#Alternative Methods using dplyr Packages
#flights <- flights %>% dplyr :: mutate(dep_datetime_alt = paste(paste(year, month, day, sep = "="),paste(hour, minute, "0", sep = ";"),sep = " "))
#head(flights)
#flights_sub <- subset(flights, dep_datetime < ymd_hm("2013-02-28 05:53"))
```

b)  Merge or join the subtable from a. `flights` data, to produce a result that includes:  
   *  Departure time
   *  Carrier (two digit code, from `carrier`)
   *  Flight number
   *  Destination airport name (hint: you will need to get this from the `airports` table)  

```{r}
#Load the airports table
airports <- read.csv("nycflights13/airports.csv")
head(airports)

#Merging two tables
head(flights_sub[,-1])
tmp <- merge(flights_sub[,-1],airports[,-1], by.x = "dest", by.y = "faa", all.x = TRUE)

#Demonstration
nodup <- flights_sub[!duplicated(flights_sub$dest),]
dtmp <- merge(nodup, airports, by.x = "dest", by.y = "faa", all.x = TRUE)
dtmp %>% dplyr :: select(dest,name) %>% head()

#Checking if Merging is Successful
length(tmp$dest)
length(flights_sub$dest)
length(airports$faa)
names(tmp)
answer2 <- select(tmp,c("dep_time", "carrier", "flight", "name"))

#Alternative Way
#answer2 <- tmp %>% dplyr :: select("dep_time", "carrier", "flight", "name")
print(answer2)
```

c) **(optional)** For every airline that had flights in the `flights` data compute the average age of the planes it flew from the entire dataset.  Age here will be defined as 2013 minus the `year` variable from the `planes` data.  Hint: This involves a join operation on `tailnum`, but also a grouped mean to compute the age (and subtracting 2013, which you can do before or after the computation of the mean).


```{r}
## your code
planes <- read.csv("nycflights13/planes.csv")

tmp1 <- flights %>% 
  filter(!duplicated(tailnum)) %>% 
  select(c("tailnum", "carrier") ) %>% 
  left_join(planes, by = "tailnum")

airlines <- read.csv("nycflights13/airlines.csv")

tmp1 %>% group_by(carrier) %>% 
  summarize(mean_age = mean(2013 - year, na.rm = TRUE)) %>%
  left_join(airlines, by = "carrier") %>% 
  select(c("name", "mean_age"))
```

### 3.  Working with SQL

a)  Create a relational dataset in SQLite using the `.csv` data found [here](nycflights13/).  Name each table so that it matches the base filenames of the input data.  You can use DB Browser for this, but describe how you did it, but the answer will use the R package [RSQLite](https://cran.r-project.org/web/packages/RSQLite/RSQLite.pdf). 

```{r}
library("RSQLite")
mydb <- dbConnect(SQLite(), "")

dbWriteTable(mydb, "flights", read.csv("nycflights13/flights.csv"))
dbWriteTable(mydb, "airlines", read.csv("nycflights13/airlines.csv"))
dbWriteTable(mydb, "airports", read.csv("nycflights13/airports.csv"))
dbWriteTable(mydb, "weather", read.csv("nycflights13/weather.csv"))
dbWriteTable(mydb, "planes", read.csv("nycflights13/planes.csv"))
```

b)  Replicate 2B above using an SQL query, including both the command and the output.

```{r}
# dep_datetime is stored as the epoch second
# calculate the epoch sec with as.integer(lubridate::ymd_hm())
answer3b <- dbGetQuery(mydb, "SELECT dep_time, carrier, flight, name FROM 
            flights AS fl 
            LEFT JOIN airports AS ap ON
            fl.dest = ap.faa
            WHERE fl.year = 2013 AND month = 2 AND day = 28 AND dep_time < 553")
print(answer3b)
```
c) **(optional)** Replicate 2c above using an SQL query, including both the command and the output.

```{r}
tmp2 <- dbGetQuery(mydb, "SELECT flights.carrier,
                  2013 - AVG(planes.year) FROM 
                  (SELECT DISTINCT tailnum, carrier FROM flights) AS flights 
                  LEFT JOIN planes ON flights.tailnum = planes.tailnum
                  GROUP BY flights.carrier")
tmp2
```

```{r}
tmp3 <- dbGetQuery(mydb, "SELECT flights.carrier, flights.tailnum, 
                  2013 - planes.year FROM planes 
                  LEFT JOIN (SELECT DISTINCT tailnum, carrier FROM flights) as flights 
                  ON flights.tailnum = planes.tailnum
                  ")
tmp3
```
```

